# üöÄ MODEL IMPROVEMENT - PHASE 1

**–î–∞—Ç–∞:** 2025-10-12  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥–æ—Ç–æ–≤–∞, —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–∞–ª—å–Ω–µ–π—à–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

---

## üìã –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏

### 1. ‚úÖ Feature Engineering (+38 –Ω–æ–≤—ã—Ö —Ñ–∏—á–µ–π)

**–î–æ–±–∞–≤–ª–µ–Ω–æ 38 –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Ñ–∏—á–µ–π:**

#### Lag Features (12 —Ñ–∏—á)
- `ret_1_lag1`, `ret_1_lag2`, `ret_1_lag4`, `ret_1_lag24` - –ª–∞–≥–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
- `rsi_14_lag1`, `rsi_14_lag4` - –ª–∞–≥–∏ RSI
- `bb_pct_20_2_lag1` - –ª–∞–≥–∏ Bollinger Bands
- `vol_norm_lag1`, `vol_norm_lag4` - –ª–∞–≥–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
- `ret_momentum_4`, `ret_momentum_12` - momentum —Ñ–∏—á–∏
- `rsi_change_4` - –∏–∑–º–µ–Ω–µ–Ω–∏–µ RSI

#### Time Features (11 —Ñ–∏—á)
- `hour`, `day_of_week`, `day_of_month`, `month` - –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- `hour_sin`, `hour_cos`, `dow_sin`, `dow_cos` - —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
- `is_weekend`, `is_month_start`, `is_month_end` - –±–∏–Ω–∞—Ä–Ω—ã–µ —Ñ–ª–∞–≥–∏

#### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (12 —Ñ–∏—á)
- `volume_sma_20`, `volume_ratio` - volume-weighted
- `high_low_ratio`, `close_open_ratio` - price action
- `atr_change`, `bb_width_change` - volatility expansion
- `ema_distance`, `ema_slope_21` - trend strength
- `price_to_sma_20` - mean reversion
- `rsi_overbought`, `rsi_oversold` - binary signals

**–ò—Ç–æ–≥–æ —Ñ–∏—á–µ–π:** 112 (–±—ã–ª–æ 74, +38 –Ω–æ–≤—ã—Ö)  
**–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Ñ–∏—á–µ–π:** ~65  

**–§–∞–π–ª—ã:** `src/features.py` (–æ–±–Ω–æ–≤–ª–µ–Ω)

---

### 2. ‚úÖ Ensemble Models Infrastructure

**–°–æ–∑–¥–∞–Ω –º–æ–¥—É–ª—å `src/ensemble.py` —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:**
- **XGBoost** - –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
- **LightGBM** - –±—ã—Å—Ç—Ä–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
- **CatBoost** - —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏
- **Voting Ensemble** - —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π 3 –º–æ–¥–µ–ª–µ–π
- **Stacking Ensemble** - –º–µ—Ç–∞-–º–æ–¥–µ–ª—å (LogisticRegression) –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö

**–§—É–Ω–∫—Ü–∏–∏:**
- `train_single_model()` - –æ–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
- `train_voting_ensemble()` - voting –∞–Ω—Å–∞–º–±–ª—å
- `train_stacking_ensemble()` - stacking –∞–Ω—Å–∞–º–±–ª—å
- `save_ensemble()`, `load_ensemble()` - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞
- `predict_ensemble()` - inference

**–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
- `lightgbm>=4.0` ‚úÖ (—É–∂–µ –≤ requirements.txt)
- `catboost>=1.2` ‚úÖ (—É–∂–µ –≤ requirements.txt)

**–§–∞–π–ª—ã:** `src/ensemble.py` (–Ω–æ–≤—ã–π, 274 —Å—Ç—Ä–æ–∫–∏)

---

### 3. ‚úÖ Hyperparameter Tuning (Optuna)

**–°–æ–∑–¥–∞–Ω —Å–∫—Ä–∏–ø—Ç `scripts/train_ensemble_optimized.py`:**
- Optuna optimization –¥–ª—è XGBoost, LightGBM, CatBoost (–ø–æ 10-33 trials –∫–∞–∂–¥—ã–π)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ ROC AUC
- –û–±—É—á–µ–Ω–∏–µ Voting –∏ Stacking ensemble –Ω–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**
- `n_estimators`: 100-500
- `max_depth`: 3-10
- `learning_rate`: 0.01-0.3 (log scale)
- `subsample`: 0.6-1.0
- `colsample_bytree`: 0.6-1.0
- –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è: `reg_alpha`, `reg_lambda`, `gamma`

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
- N_TRIALS: 30 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 100+)
- TIMEOUT: 30 –º–∏–Ω—É—Ç
- Train/Val/Test split: 60/20/20

**–§–∞–π–ª—ã:** `scripts/train_ensemble_optimized.py` (–Ω–æ–≤—ã–π, 283 —Å—Ç—Ä–æ–∫–∏)

---

### 4. ‚úÖ Testing Scripts

**scripts/test_new_features.py** - –±—ã—Å—Ç—Ä–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –∏ –Ω–æ–≤—ã—Ö —Ñ–∏—á–µ–π:
- –û–±—É—á–∞–µ—Ç XGBoost –Ω–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∏—á–∞—Ö (28 —Ñ–∏—á)
- –û–±—É—á–∞–µ—Ç XGBoost –Ω–∞ –≤—Å–µ—Ö —Ñ–∏—á–∞—Ö (112 —Ñ–∏—á)
- –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç AUC improvement

**scripts/backtest_improved_model.py** - –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏:
- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ 80% –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç –Ω–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è 20%
- –ú–µ—Ç—Ä–∏–∫–∏: Sharpe, Sortino, Calmar, Max DD, Win Rate, Profit Factor
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–µ–π: Sharpe >1.5, Return >5%

**–§–∞–π–ª—ã:** 
- `scripts/test_new_features.py` (–Ω–æ–≤—ã–π, 169 —Å—Ç—Ä–æ–∫)
- `scripts/backtest_improved_model.py` (–Ω–æ–≤—ã–π, 206 —Å—Ç—Ä–æ–∫)

---

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

### Test 1: Feature Comparison (Old vs New)

```
Old features: 28
New features: 84
Total features: 112

Old Model:
  Accuracy: 0.4789
  ROC AUC:  0.4765

New Model (with all features):
  Accuracy: 0.4789
  ROC AUC:  0.4848

Improvement: +0.84% AUC
```

**–í—ã–≤–æ–¥:** –ù–æ–≤—ã–µ —Ñ–∏—á–∏ –¥–∞—é—Ç –Ω–µ–±–æ–ª—å—à–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ (+0.84% AUC), –Ω–æ –º–æ–¥–µ–ª—å –≤—Å–µ –µ—â–µ —Å–ª–∞–±–∞—è.

---

### Test 2: Backtest (Improved Model)

```
Dataset: 2129 rows, 2025-07-15 to 2025-10-12 (89 days)
Train: 1703 samples (80%)
Test: 426 samples (20%)

Results:
  Total Return:    -2.56%
  Sharpe Ratio:    -1.98
  Sortino Ratio:   -1.14
  Calmar Ratio:    -0.49
  Max Drawdown:    -5.22%
  Win Rate:        48.15%
  Profit Factor:   0.85
  Total Trades:    81

Goal Check:
  Sharpe >1.5: ‚úó (-1.98)
  Return >5%:  ‚úó (-2.56%)
```

**–í—ã–≤–æ–¥:** –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å XGBoost —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —É–±—ã—Ç–æ—á–Ω–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è:
1. Hyperparameter tuning (Optuna)
2. Ensemble approach
3. Feature selection (—É–±—Ä–∞—Ç—å —Å—Ç–∞—Ç–∏—á–Ω—ã–µ on-chain/macro/social —Ñ–∏—á–∏)

---

## üîç –í—ã–≤–æ–¥—ã

### –ß—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚úÖ
1. **Feature Engineering –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞** - –¥–æ–±–∞–≤–ª–µ–Ω–æ 38 –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Ñ–∏—á–µ–π
2. **Ensemble –º–æ–¥—É–ª–∏** - –≥–æ—Ç–æ–≤—ã XGBoost, LightGBM, CatBoost, Voting, Stacking
3. **Optuna hyperparameter tuning** - —Å–∫—Ä–∏–ø—Ç –≥–æ—Ç–æ–≤ –∫ –∑–∞–ø—É—Å–∫—É
4. **–¢–µ—Å—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã** - –º–æ–∂–Ω–æ –±—ã—Å—Ç—Ä–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —É–ª—É—á—à–µ–Ω–∏—è

### –ß—Ç–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚ùå
1. **–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —É–±—ã—Ç–æ—á–Ω–∞** - Sharpe -1.98, Return -2.56%
2. **AUC <0.5** - –º–æ–¥–µ–ª—å —Ö—É–∂–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —É–≥–∞–¥—ã–≤–∞–Ω–∏—è
3. **–î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã**

### –ü–æ—á–µ–º—É –º–æ–¥–µ–ª—å —Å–ª–∞–±–∞—è? ü§î
1. **–°—Ç–∞—Ç–∏—á–Ω—ã–µ —Ñ–∏—á–∏** - On-chain/Macro/Social –≤—ã–∑—ã–≤–∞—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
   - –†–µ—à–µ–Ω–∏–µ: —É–±—Ä–∞—Ç—å –∏—Ö –∏–ª–∏ —Å–¥–µ–ª–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ (API –≤—ã–∑–æ–≤—ã –Ω–∞ –∫–∞–∂–¥—ã–π timestamp)
2. **–ù–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** - –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
   - –†–µ—à–µ–Ω–∏–µ: –∑–∞–ø—É—Å—Ç–∏—Ç—å Optuna —Å –±–æ–ª—å—à–∏–º budget (100+ trials)
3. **–°–ª–∞–±—ã–π signal** - –≤–æ–∑–º–æ–∂–Ω–æ horizon_steps=4 —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
   - –†–µ—à–µ–Ω–∏–µ: –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å horizon_steps=12 –∏–ª–∏ 24
4. **Overfitting** - –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ train
   - –†–µ—à–µ–Ω–∏–µ: Walk-Forward Validation, –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (PHASE 2)

### –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ (–∫—Ä–∏—Ç–∏—á–Ω–æ)
1. **–ó–∞–ø—É—Å—Ç–∏—Ç—å Optuna optimization** —Å N_TRIALS=100+
   ```bash
   python scripts/train_ensemble_optimized.py
   ```
2. **Feature Selection** - —É–±—Ä–∞—Ç—å —Å—Ç–∞—Ç–∏—á–Ω—ã–µ on-chain/macro/social —Ñ–∏—á–∏
3. **–£–≤–µ–ª–∏—á–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç** - –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö

### –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ (1-2 –¥–Ω—è)
4. **Walk-Forward Validation** - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
5. **Ensemble training** - —Å—Ä–∞–≤–Ω–∏—Ç—å Voting vs Stacking
6. **Threshold optimization** - –ø–æ–¥–æ–±—Ä–∞—Ç—å –ø–æ—Ä–æ–≥ –¥–ª—è BUY —Å–∏–≥–Ω–∞–ª–∞ (–Ω–µ 0.5)
7. **Position sizing** - Kelly Criterion –∏–ª–∏ RL-based

### –°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω–æ (3-7 –¥–Ω–µ–π)
8. **RL Agent integration** (PHASE 2 –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —á–∞—Ç–∞)
9. **Multi-timeframe analysis** - –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å 1h + 4h + 1d —Å–∏–≥–Ω–∞–ª—ã
10. **Dynamic feature updates** - —Ä–µ–∞–ª—å–Ω—ã–µ on-chain/macro/social —á–µ—Ä–µ–∑ API

---

## üìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

### –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã
- `src/ensemble.py` - ensemble models (274 —Å—Ç—Ä–æ–∫–∏)
- `scripts/train_ensemble_optimized.py` - Optuna training (283 —Å—Ç—Ä–æ–∫–∏)
- `scripts/test_new_features.py` - feature comparison (169 —Å—Ç—Ä–æ–∫)
- `scripts/backtest_improved_model.py` - backtesting (206 —Å—Ç—Ä–æ–∫)
- `docs/MODEL_IMPROVEMENT_PHASE1.md` - —ç—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
- `src/features.py` - –¥–æ–±–∞–≤–ª–µ–Ω–æ 38 –Ω–æ–≤—ã—Ö —Ñ–∏—á–µ–π (+150 —Å—Ç—Ä–æ–∫)

**–ò—Ç–æ–≥–æ:** ~1080 —Å—Ç—Ä–æ–∫ –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞

---

## üìù –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è PHASE 2

### 1. Feature Selection (—É–±—Ä–∞—Ç—å —Å—Ç–∞—Ç–∏—á–Ω—ã–µ —Ñ–∏—á–∏)

```python
# –í src/features.py - –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ —É—Å–ª–æ–≤–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å:
# - onchain_* —Ñ–∏—á–∏ (13 —Ñ–∏—á) - —Å—Ç–∞—Ç–∏—á–Ω—ã–µ
# - macro_* —Ñ–∏—á–∏ (9 —Ñ–∏—á) - —Å—Ç–∞—Ç–∏—á–Ω—ã–µ
# - social_* —Ñ–∏—á–∏ (6 —Ñ–∏—á) - —Å—Ç–∞—Ç–∏—á–Ω—ã–µ

# –ò—Ç–æ–≥–æ: 112 ‚Üí 84 —Ñ–∏—á–∏ (—É–±–∏—Ä–∞–µ–º 28 —Å—Ç–∞—Ç–∏—á–Ω—ã—Ö)
```

### 2. –ó–∞–ø—É—Å–∫ Optuna —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º budget

```python
# scripts/train_ensemble_optimized.py
N_TRIALS = 150  # –ø–æ 50 trials –Ω–∞ –º–æ–¥–µ–ª—å
TIMEOUT = 7200  # 2 —á–∞—Å–∞
```

### 3. –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞

```python
# –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç—ã:
horizon_steps = 4   # —Ç–µ–∫—É—â–∏–π (4 —á–∞—Å–∞)
horizon_steps = 12  # 12 —á–∞—Å–æ–≤
horizon_steps = 24  # 1 –¥–µ–Ω—å
```

### 4. Kelly Criterion –¥–ª—è position sizing

```python
# –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è win_rate –∏ profit_factor:
kelly_fraction = (win_rate * avg_win - (1 - win_rate) * avg_loss) / avg_win
position_size = kelly_fraction * capital
```

---

## ‚è± –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

- Feature Engineering: ~30 –º–∏–Ω—É—Ç
- Ensemble infrastructure: ~45 –º–∏–Ω—É—Ç
- Optuna script: ~30 –º–∏–Ω—É—Ç
- Testing scripts: ~30 –º–∏–Ω—É—Ç
- Testing & debugging: ~1 —á–∞—Å
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: ~20 –º–∏–Ω—É—Ç

**–ò—Ç–æ–≥–æ:** ~3.5 —á–∞—Å–∞

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

- **–ù–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤:** 5
- **–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:** 1
- **–°—Ç—Ä–æ–∫ –∫–æ–¥–∞:** ~1080
- **–ù–æ–≤—ã—Ö —Ñ–∏—á–µ–π:** +38
- **–ù–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π:** 5 (XGB, LGBM, CAT, Voting, Stacking)
- **–ù–æ–≤—ã—Ö —Å–∫—Ä–∏–ø—Ç–æ–≤:** 3

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è PHASE 1

- [x] –î–æ–±–∞–≤–ª–µ–Ω—ã lag features
- [x] –î–æ–±–∞–≤–ª–µ–Ω—ã time features
- [x] –î–æ–±–∞–≤–ª–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
- [x] –°–æ–∑–¥–∞–Ω ensemble –º–æ–¥—É–ª—å (XGBoost + LightGBM + CatBoost)
- [x] –°–æ–∑–¥–∞–Ω Optuna hyperparameter tuning —Å–∫—Ä–∏–ø—Ç
- [x] –°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
- [x] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –Ω–æ–≤—ã–µ —Ñ–∏—á–∏ (baseline comparison)
- [x] –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤—Å—è —Ä–∞–±–æ—Ç–∞

**PHASE 1 –ó–ê–í–ï–†–®–ï–ù–ê!** ‚úÖ

---

**–°–ª–µ–¥—É—é—â–∞—è —Ñ–∞–∑–∞:** PHASE 2 - Hyperparameter Optimization + Feature Selection (–æ—Ç–¥–µ–ª—å–Ω—ã–π —á–∞—Ç)

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-12  
**–ê–≤—Ç–æ—Ä:** AI Assistant (Claude Sonnet 4.5)

