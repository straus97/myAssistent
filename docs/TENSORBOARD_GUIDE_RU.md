# üéÆ TensorBoard - –†—É—Å—Å–∫–∏–π –ì–∞–π–¥ –¥–ª—è RL –û–±—É—á–µ–Ω–∏—è

**URL:** http://localhost:6006  
**–ß—Ç–æ —ç—Ç–æ:** –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ RL-–∞–≥–µ–Ω—Ç–æ–≤

---

## üéØ –ß–¢–û –¢–ê–ö–û–ï TENSORBOARD?

**TensorBoard** - –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è RL/DL –º–æ–¥–µ–ª–µ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:
- üìà –ì—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫ (–Ω–∞–≥—Ä–∞–¥–∞, loss, learning rate)
- üéÆ –ü—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è PPO agent
- üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º (–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, –º–µ–¥–ª–µ–Ω–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å)

---

## üöÄ –ö–ê–ö –ó–ê–ü–£–°–¢–ò–¢–¨

### 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å TensorBoard

```bash
# –í –ù–û–í–û–ú —Ç–µ—Ä–º–∏–Ω–∞–ª–µ PowerShell
cd C:\AI\myAssistent
.\.venv\Scripts\activate
tensorboard --logdir artifacts/tensorboard
```

**Output:**
```
TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)
```

### 2. –û—Ç–∫—Ä—ã—Ç—å –≤ –±—Ä–∞—É–∑–µ—Ä–µ

```
http://localhost:6006
```

---

## üñ•Ô∏è –ò–ù–¢–ï–†–§–ï–ô–° TENSORBOARD

–ü–æ—Å–ª–µ –æ—Ç–∫—Ä—ã—Ç–∏—è —É–≤–∏–¥–∏—à—å **–≤–∫–ª–∞–¥–∫–∏** (tabs):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Scalars ‚îÇ Graphs ‚îÇ Distributions ‚îÇ ...     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä –ì–õ–ê–í–ù–´–ï –í–ö–õ–ê–î–ö–ò

### 1. Scalars (–ì—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫) - –û–°–ù–û–í–ù–ê–Ø

**–ß—Ç–æ –ø–æ–∫–∞–∑–∞–Ω–æ:**

#### –°–µ–∫—Ü–∏—è `rollout/` - –ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è

| –ì—Ä–∞—Ñ–∏–∫ | –û–ø–∏—Å–∞–Ω–∏–µ | –ß—Ç–æ —Å–º–æ—Ç—Ä–µ—Ç—å |
|--------|----------|--------------|
| **ep_rew_mean** | –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ —ç–ø–∏–∑–æ–¥ | –î–æ–ª–∂–Ω–∞ **—Ä–∞—Å—Ç–∏** ‚ÜóÔ∏è |
| **ep_len_mean** | –î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞ | –°—Ç–∞–±–∏–ª—å–Ω–∞ –∏–ª–∏ —Ä–∞—Å—Ç–µ—Ç |

**–ü—Ä–∏–º–µ—Ä:**

```
ep_rew_mean
  ‚îÇ
5 ‚îÇ         ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚Üê –•–æ—Ä–æ—à–æ! –ù–∞–≥—Ä–∞–¥–∞ —Ä–∞—Å—Ç–µ—Ç
  ‚îÇ       ‚ï±
0 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±            ‚Üê –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è
  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   0    50K   100K  (timesteps)
```

‚úÖ **–•–æ—Ä–æ—à–æ:** –ì—Ä–∞—Ñ–∏–∫ –∏–¥–µ—Ç –≤–≤–µ—Ä—Ö  
‚ö†Ô∏è **–ü–ª–æ—Ö–æ:** –ì—Ä–∞—Ñ–∏–∫ –ø–∞–¥–∞–µ—Ç –∏–ª–∏ –ø–ª–æ—Å–∫–∏–π

---

#### –°–µ–∫—Ü–∏—è `train/` - –î–µ—Ç–∞–ª–∏ –æ–±—É—á–µ–Ω–∏—è

| –ì—Ä–∞—Ñ–∏–∫ | –û–ø–∏—Å–∞–Ω–∏–µ | –ß—Ç–æ —Å–º–æ—Ç—Ä–µ—Ç—å |
|--------|----------|--------------|
| **loss** | –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å | –î–æ–ª–∂–Ω–∞ **–ø–∞–¥–∞—Ç—å** ‚ÜòÔ∏è |
| **learning_rate** | –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è | –û–±—ã—á–Ω–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (3e-4) |
| **entropy_loss** | –≠–Ω—Ç—Ä–æ–ø–∏—è –¥–µ–π—Å—Ç–≤–∏–π | –ü–∞–¥–∞–µ—Ç (agent —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —É–≤–µ—Ä–µ–Ω–Ω—ã–º) |
| **policy_loss** | Policy gradient loss | –ö–æ–ª–µ–±–ª–µ—Ç—Å—è, –Ω–æ —Å–Ω–∏–∂–∞–µ—Ç—Å—è |
| **value_loss** | Value function loss | –°–Ω–∏–∂–∞–µ—Ç—Å—è |

**–ü—Ä–∏–º–µ—Ä:**

```
loss
  ‚îÇ
1 ‚îÇ‚ï≤                  ‚Üê –•–æ—Ä–æ—à–æ! Loss –ø–∞–¥–∞–µ—Ç
  ‚îÇ ‚ï≤
  ‚îÇ  ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚Üê –°—Ö–æ–¥–∏–º–æ—Å—Ç—å
0 ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   0    50K   100K
```

---

### 2. Graphs (–ì—Ä–∞—Ñ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π)

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ PPO:
- Input layer (features)
- Hidden layers (policy/value networks)
- Output layer (actions)

**–î–ª—è –Ω–∞—Å:** –ü—Ä–æ—Å—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ.

---

### 3. Distributions (–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø–æ timesteps.

**–î–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:**
- –í–µ—Å–∞ –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—Å–µ –Ω—É–ª–∏
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –º–µ–Ω—è—Ç—å—Å—è (–æ–±—É—á–µ–Ω–∏–µ –∏–¥–µ—Ç)

---

## üéØ –ö–ê–ö –ü–û–ù–Ø–¢–¨, –ß–¢–û –û–ë–£–ß–ï–ù–ò–ï –ò–î–ï–¢ –•–û–†–û–®–û?

### ‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –•–û–†–û–®–ï–ì–û –æ–±—É—á–µ–Ω–∏—è

1. **ep_rew_mean —Ä–∞—Å—Ç–µ—Ç** ‚ÜóÔ∏è
   - –ù–∞–≥—Ä–∞–¥–∞ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º
   - –ó–Ω–∞—á–∏—Ç agent —É—á–∏—Ç—Å—è –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å

2. **loss –ø–∞–¥–∞–µ—Ç** ‚ÜòÔ∏è
   - –ú–æ–¥–µ–ª—å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ç–æ—á–Ω–µ–µ
   - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É–ª—É—á—à–∞—é—Ç—Å—è

3. **entropy_loss —Å–Ω–∏–∂–∞–µ—Ç—Å—è**
   - Agent —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —É–≤–µ—Ä–µ–Ω–Ω–µ–µ –≤ –¥–µ–π—Å—Ç–≤–∏—è—Ö
   - –ú–µ–Ω—å—à–µ —Å–ª—É—á–∞–π–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π

4. **–ù–µ—Ç —Ä–µ–∑–∫–∏—Ö —Å–∫–∞—á–∫–æ–≤**
   - –ì—Ä–∞—Ñ–∏–∫–∏ –ø–ª–∞–≤–Ω—ã–µ
   - –û–±—É—á–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ

---

### ‚ö†Ô∏è –ü—Ä–∏–∑–Ω–∞–∫–∏ –ü–†–û–ë–õ–ï–ú

1. **ep_rew_mean –Ω–µ —Ä–∞—Å—Ç–µ—Ç** (–ø–ª–æ—Å–∫–∏–π –≥—Ä–∞—Ñ–∏–∫)
   - Agent –Ω–µ —É—á–∏—Ç—Å—è
   - –í–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å reward function

2. **ep_rew_mean –ø–∞–¥–∞–µ—Ç** ‚ÜòÔ∏è
   - Agent –¥–µ–≥—Ä–∞–¥–∏—Ä—É–µ—Ç (—Ä–µ–¥–∫–æ)
   - –ù—É–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å learning_rate

3. **–†–µ–∑–∫–∏–µ —Å–∫–∞—á–∫–∏** (–ø–∏–ª–∞)
   - –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
   - –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã

4. **NaN values** (Not a Number)
   - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
   - –ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

---

## üìà –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –ì–†–ê–§–ò–ö–û–í

### –ü—Ä–∏–º–µ—Ä 1: –£—Å–ø–µ—à–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```
ep_rew_mean
  ‚îÇ
5 ‚îÇ              ‚ï±‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚Üê –î–æ—Å—Ç–∏–≥–ª–∞ plateau (—Ö–æ—Ä–æ—à–æ!)
  ‚îÇ           ‚ï±
  ‚îÇ        ‚ï±
0 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±                 ‚Üê –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ
  ‚îÇ
-5‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   0   25K  50K  75K  100K
```

**–ß—Ç–æ –≤–∏–¥–∏–º:**
- –ù–∞–≥—Ä–∞–¥–∞ —Ä–∞—Å—Ç–µ—Ç —Å 0 –¥–æ 5
- –î–æ—Å—Ç–∏–≥–ª–∞ plateau (—Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∞—Å—å)
- ‚úÖ **Agent –æ–±—É—á–∏–ª—Å—è!**

---

### –ü—Ä–∏–º–µ—Ä 2: –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

```
ep_rew_mean
  ‚îÇ
2 ‚îÇ                    ‚ï±‚îÄ  ‚Üê –ú–µ–¥–ª–µ–Ω–Ω–æ —Ä–∞—Å—Ç–µ—Ç
  ‚îÇ                 ‚ï±
  ‚îÇ              ‚ï±
0 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ï±
  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   0   25K  50K  75K  100K
```

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
- ‚è∞ –ü–æ–¥–æ–∂–¥–∞—Ç—å –¥–æ–ª—å—à–µ (—É–≤–µ–ª–∏—á–∏—Ç—å timesteps –¥–æ 500K)
- üîß –£–≤–µ–ª–∏—á–∏—Ç—å learning_rate (3e-4 ‚Üí 5e-4)

---

### –ü—Ä–∏–º–µ—Ä 3: –ù–µ —É—á–∏—Ç—Å—è

```
ep_rew_mean
  ‚îÇ
0 ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚Üê –ü–ª–æ—Å–∫–∞—è –ª–∏–Ω–∏—è
  ‚îÇ
  ‚îÇ
-2‚îÇ
  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
   0   25K  50K  75K  100K
```

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
- ‚ùå –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–ª–∏–ª–æ—Å—å
- üîÑ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π reward function
- üîÑ –£–≤–µ–ª–∏—á–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç
- üîÑ –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º (A2C, SAC)

---

## üéÆ –ù–ê–®–ò –ú–ï–¢–†–ò–ö–ò RL

### Reward Function (–ù–∞–≥—Ä–∞–¥–∞)

**–ß—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º:**
```python
reward = Sharpe Ratio (rolling 30-day window)
```

**–¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:**
- Sharpe > 0.5 ‚ö†Ô∏è –ü—Ä–∏–µ–º–ª–µ–º–æ
- Sharpe > 1.0 ‚úÖ –•–æ—Ä–æ—à–æ
- Sharpe > 1.5 üèÜ –û—Ç–ª–∏—á–Ω–æ

**–ù–∞ –≥—Ä–∞—Ñ–∏–∫–µ `ep_rew_mean`:**
- –ó–Ω–∞—á–µ–Ω–∏–µ 0.5-1.0 = agent —É—á–∏—Ç—Å—è –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
- –ó–Ω–∞—á–µ–Ω–∏–µ >1.0 = agent —Ö–æ—Ä–æ—à
- –ó–Ω–∞—á–µ–Ω–∏–µ <0 = agent —Ç–µ—Ä—è–µ—Ç –¥–µ–Ω—å–≥–∏

---

### Actions (–î–µ–π—Å—Ç–≤–∏—è)

**PPO agent –≤—ã–±–∏—Ä–∞–µ—Ç:**
1. **Direction:** Hold (0) / Buy (1) / Sell (2)
2. **Sizing:** 1-20% –æ—Ç –∫–∞–ø–∏—Ç–∞–ª–∞

**–ù–∞ –≥—Ä–∞—Ñ–∏–∫–µ `action_distribution`:**
- –í–∏–¥–Ω–æ, –∫–∞–∫–∏–µ –¥–µ–π—Å—Ç–≤–∏—è agent –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç
- –ï—Å–ª–∏ –≤—Å–µ actions = Hold ‚Üí agent –Ω–µ —Ç–æ—Ä–≥—É–µ—Ç (–ø–ª–æ—Ö–æ)
- –ï—Å–ª–∏ mixed Buy/Sell ‚Üí agent –∞–∫—Ç–∏–≤–Ω—ã–π (—Ö–æ—Ä–æ—à–æ)

---

## üí° –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –°–û–í–ï–¢–´

### –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è

```bash
# –ö–∞–∂–¥—ã–µ 10-15 –º–∏–Ω—É—Ç:
1. –û—Ç–∫—Ä–æ–π http://localhost:6006
2. –ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ ep_rew_mean
3. –ï—Å–ª–∏ —Ä–∞—Å—Ç–µ—Ç ‚ÜóÔ∏è ‚Üí –≤—Å–µ —Ö–æ—Ä–æ—à–æ, –∂–¥–∏ –¥–∞–ª—å—à–µ
4. –ï—Å–ª–∏ –ø–ª–æ—Å–∫–∏–π ‚îÄ ‚Üí –≤–æ–∑–º–æ–∂–Ω–æ, –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
```

---

### –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è

```bash
# –ü–æ—Å–º–æ—Ç—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:
1. ep_rew_mean (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞)
2. loss (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∏–∑–∫–∏–º, <1.0)
3. –°—Ä–∞–≤–Ω–∏ —Å —Ü–µ–ª—å—é (Sharpe >1.0)
```

---

### –ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–ª–∏–ª–æ—Å—å

```bash
# –ü–æ–ø—Ä–æ–±—É–π:
1. –£–≤–µ–ª–∏—á–∏—Ç—å timesteps (100K ‚Üí 500K)
2. –ò–∑–º–µ–Ω–∏—Ç—å learning_rate (3e-4 ‚Üí 1e-4)
3. –ò–∑–º–µ–Ω–∏—Ç—å reward function (–¥—Ä—É–≥–∞—è —Ñ–æ—Ä–º—É–ª–∞)
4. –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
```

---

## üîß –ö–û–ú–ê–ù–î–´

### –ó–∞–ø—É—Å—Ç–∏—Ç—å TensorBoard

```bash
tensorboard --logdir artifacts/tensorboard
```

### –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–∞ –¥—Ä—É–≥–æ–º –ø–æ—Ä—Ç—É

```bash
tensorboard --logdir artifacts/tensorboard --port 6007
```

### –°—Ä–∞–≤–Ω–∏—Ç—å —Ä–∞–∑–Ω—ã–µ runs

```bash
# TensorBoard –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–∫–∞–∂–µ—Ç –≤—Å–µ runs –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
# –ü—Ä–æ—Å—Ç–æ –≤—ã–±–µ—Ä–∏ –Ω—É–∂–Ω—ã–µ –≤ dropdown (–≤–≤–µ—Ä—Ö—É —Å–ø—Ä–∞–≤–∞)
```

---

## üìÅ –ì–î–ï –î–ê–ù–ù–´–ï?

```
artifacts/tensorboard/
‚îú‚îÄ‚îÄ PPO_1/  # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ RL
‚îÇ   ‚îî‚îÄ‚îÄ events.out.tfevents.*
‚îú‚îÄ‚îÄ PPO_2/  # –í—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ RL
‚îÇ   ‚îî‚îÄ‚îÄ events.out.tfevents.*
‚îî‚îÄ‚îÄ PPO_X/  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫
    ‚îî‚îÄ‚îÄ events.out.tfevents.*
```

–ö–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫ `scripts/train_rl_ppo.py` —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –ø–∞–ø–∫—É.

---

## üéØ –ü–†–ò–ú–ï–† –†–ï–ê–õ–¨–ù–û–ì–û –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø

### –°—Ü–µ–Ω–∞—Ä–∏–π: –ü—Ä–æ–≤–µ—Ä–∫–∞ RL –æ–±—É—á–µ–Ω–∏—è

1. **–ó–∞–ø—É—Å—Ç–∏–ª –æ–±—É—á–µ–Ω–∏–µ:**
   ```bash
   python scripts\train_rl_ppo.py --timesteps 100000
   ```

2. **–û—Ç–∫—Ä—ã–ª TensorBoard:**
   ```bash
   tensorboard --logdir artifacts/tensorboard
   # http://localhost:6006
   ```

3. **–°–º–æ—Ç—Ä—é –≥—Ä–∞—Ñ–∏–∫ `ep_rew_mean` –∫–∞–∂–¥—ã–µ 15 –º–∏–Ω—É—Ç:**
   - 0-25K timesteps: –Ω–∞–≥—Ä–∞–¥–∞ –∫–æ–ª–µ–±–ª–µ—Ç—Å—è (exploration)
   - 25K-75K: –Ω–∞–≥—Ä–∞–¥–∞ —Ä–∞—Å—Ç–µ—Ç (learning)
   - 75K-100K: –Ω–∞–≥—Ä–∞–¥–∞ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞–ª–∞—Å—å (convergence)

4. **–§–∏–Ω–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞: 1.2 (Sharpe Ratio)**
   - ‚úÖ –¶–µ–ª—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ (>1.0)!
   - Agent –≥–æ—Ç–æ–≤ –∫ paper trading

---

## ‚ùì –ß–ê–°–¢–´–ï –í–û–ü–†–û–°–´

### TensorBoard –ø—É—Å—Ç–æ–π?

**–ü—Ä–∏—á–∏–Ω—ã:**
1. –û–±—É—á–µ–Ω–∏–µ –µ—â–µ –Ω–µ –Ω–∞—á–∞–ª–æ—Å—å (–ø–æ–¥–æ–∂–¥–∏ 1-2 –º–∏–Ω—É—Ç—ã)
2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è (`--logdir` –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å `artifacts/tensorboard`)
3. –ù–µ—Ç runs (–∑–∞–ø—É—Å—Ç–∏ `scripts/train_rl_ppo.py`)

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª—ã
dir artifacts\tensorboard\PPO_*\
```

---

### –ì—Ä–∞—Ñ–∏–∫–∏ –Ω–µ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è?

**–ü—Ä–∏—á–∏–Ω—ã:**
1. –û–±—É—á–µ–Ω–∏–µ –µ—â–µ –∏–¥–µ—Ç (TensorBoard –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫)
2. –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å (–≥—Ä–∞—Ñ–∏–∫–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ)

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –û–±–Ω–æ–≤–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É (F5)
# –ò–ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ TensorBoard
```

---

### –ö–∞–∫ —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ RL –∑–∞–ø—É—Å–∫–∞?

**–í TensorBoard:**
1. –°–ª–µ–≤–∞ –≤ dropdown "Runs" –≤—ã–±–µ—Ä–∏ –æ–±–∞
2. –ì—Ä–∞—Ñ–∏–∫–∏ –ø–æ–∫–∞–∂—É—Ç –¥–≤–µ –ª–∏–Ω–∏–∏ (—Ä–∞–∑–Ω—ã–µ —Ü–≤–µ—Ç–∞)
3. –°—Ä–∞–≤–Ω–∏ ep_rew_mean (–∫–∞–∫–æ–π agent –ª—É—á—à–µ)

---

## üéâ –ò–¢–û–ì–û

**TensorBoard** = –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ RL –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

**–ì–ª–∞–≤–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫:** `ep_rew_mean` (—Å—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞)
- –†–∞—Å—Ç–µ—Ç ‚ÜóÔ∏è = agent —É—á–∏—Ç—Å—è ‚úÖ
- –ü–ª–æ—Å–∫–∏–π ‚îÄ = –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ ‚è∞
- –ü–∞–¥–∞–µ—Ç ‚ÜòÔ∏è = –ø—Ä–æ–±–ª–µ–º—ã ‚ùå

**–¶–µ–ª—å:** ep_rew_mean >1.0 (Sharpe Ratio >1.0)

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-12  
**–ê–≤—Ç–æ—Ä:** MyAssistent Team

