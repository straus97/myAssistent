# üîß Model Improvement PHASE 3: Cross-Validation –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è Overfitting

**–î–∞—Ç–∞:** 2025-10-12 (–≤–µ—á–µ—Ä)  
**–°—Ç–∞—Ç—É—Å:** –°–∫—Ä–∏–ø—Ç—ã –≥–æ—Ç–æ–≤—ã, –æ–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞  
**–¶–µ–ª—å:** –ò—Å–ø—Ä–∞–≤–∏—Ç—å overfitting, –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –≤ PHASE 2

---

## üö® –ü–†–û–ë–õ–ï–ú–ê PHASE 2

### Overfitting –°–∏–º–ø—Ç–æ–º—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | Validation | Test | –ü—Ä–æ–±–ª–µ–º–∞ |
|---------|-----------|------|----------|
| **ROC AUC** | 0.6538 | 0.4829 | Test —Ö—É–∂–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ (0.5)! |
| **Improvement** | +35% | -3.4% | Validation –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É—Å–ø–µ—Ö, Test - –ø—Ä–æ–≤–∞–ª |

### –ü—Ä–∏—á–∏–Ω–∞

Optuna –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã **–ø–æ–¥ validation set**, —á—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫:
1. –ú–æ–¥–µ–ª—å "–∑–∞–ø–æ–º–Ω–∏–ª–∞" validation patterns
2. –ù–µ –æ–±–æ–±—â–∞–µ—Ç—Å—è –Ω–∞ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (test set)
3. –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä overfitting

---

## ‚úÖ –†–ï–®–ï–ù–ò–ï PHASE 3

### 1. TimeSeriesSplit (5-fold CV)

–í–º–µ—Å—Ç–æ **single validation split (60/20/20)**, –∏—Å–ø–æ–ª—å–∑—É–µ–º **5-fold TimeSeriesSplit**:

```
Fold 1:  Train [0:800] ‚Üí Val [800:1000]
Fold 2:  Train [0:1000] ‚Üí Val [1000:1200]
Fold 3:  Train [0:1200] ‚Üí Val [1200:1400]
Fold 4:  Train [0:1400] ‚Üí Val [1400:1600]
Fold 5:  Train [0:1600] ‚Üí Val [1600:1800]

Test [1800:2129] ‚Äî –ù–ï–¢–†–û–ù–£–¢!
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ 5 —Ä–∞–∑–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–Ω–∞—Ö
- –ù–µ—Ç –µ–¥–∏–Ω–æ–≥–æ validation set –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

---

### 2. –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

**XGBoost (–Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã):**
```python
{
    "max_depth": 3-7,  # –ë—ã–ª–æ: 4-10
    "min_child_weight": 1-10,  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä!
    "reg_alpha": 0.0-10.0,  # L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (–±—ã–ª–æ: 0.0-1.0)
    "reg_lambda": 1.0-10.0,  # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (–±—ã–ª–æ: 1.0-5.0)
}
```

**LightGBM (–Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã):**
```python
{
    "max_depth": 3-7,
    "min_child_samples": 10-50,  # –ë—ã–ª–æ: 5-20
    "reg_alpha": 0.0-10.0,
    "reg_lambda": 1.0-10.0,
}
```

**CatBoost (–Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã):**
```python
{
    "depth": 3-7,
    "l2_leaf_reg": 1.0-10.0,  # –ë—ã–ª–æ: 1.0-5.0
    "random_strength": 0.0-2.0,  # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä!
}
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ –¥–µ—Ä–µ–≤—å—è (–º–µ–Ω—å—à–µ max_depth)
- –ë–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–∑–ª–æ–≤ (min_child_weight, min_child_samples)
- –°–∏–ª—å–Ω–∞—è L1/L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

---

### 3. Aggregation Best Params

–ü–æ—Å–ª–µ 5 folds, —É—Å—Ä–µ–¥–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

```python
def aggregate_params(params_list):
    for key in all_keys:
        if numeric:
            aggregated[key] = np.mean(values)  # –°—Ä–µ–¥–Ω–µ–µ
        else:
            aggregated[key] = Counter(values).most_common(1)[0][0]  # –ú–æ–¥–∞
    return aggregated
```

**–≠—Ñ—Ñ–µ–∫—Ç:** –ü–æ–ª—É—á–∞–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –≤—Å–µ—Ö —Ñ–æ–ª–¥–∞—Ö.

---

## üìä –ö–†–ò–¢–ï–†–ò–ò –£–°–ü–ï–•–ê

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É—Å–ø–µ—Ö ‚úÖ
- [ ] Test AUC >0.55 (improvement —Å 0.4829)
- [ ] Test AUC > Validation AUC (–Ω–µ—Ç overfitting!)
- [ ] Stable metrics –Ω–∞ –≤—Å–µ—Ö 5 CV folds (std <0.05)

### –¶–µ–ª–µ–≤–æ–π —É—Å–ø–µ—Ö üéØ
- [ ] Test AUC >0.60
- [ ] Sharpe Ratio >1.0 (–Ω–∞ backtest)
- [ ] Total Return >3% (–Ω–∞ backtest)

### –ò–¥–µ–∞–ª—å–Ω—ã–π —É—Å–ø–µ—Ö üèÜ
- [ ] Test AUC >0.65
- [ ] Sharpe Ratio >1.5
- [ ] Total Return >5%
- [ ] Ensemble –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç single models

---

## üõ† –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø

### –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã

1. **scripts/train_ensemble_cross_validation.py**
   - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (84 —Ñ–∏—á–∏)
   - Train/Test split (80/20)
   - TimeSeriesSplit (5 folds) –Ω–∞ train set
   - Optuna optimization –Ω–∞ –∫–∞–∂–¥–æ–º fold (30 trials √ó 3 models)
   - Aggregation best params
   - Training final models –Ω–∞ full train set
   - Evaluation –Ω–∞ test set
   - Comparison —Å PHASE 2

2. **src/ensemble.py (–æ–±–Ω–æ–≤–ª–µ–Ω)**
   - `optimize_xgboost_cv()` - Optuna —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
   - `optimize_lightgbm_cv()` - –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è LightGBM
   - `optimize_catboost_cv()` - –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è CatBoost
   - `train_voting_ensemble()` - VotingClassifier (sklearn)
   - `train_stacking_ensemble()` - StackingClassifier (sklearn)
   - `evaluate_ensemble()` - Metrics calculation

---

## üöÄ –ó–ê–ü–£–°–ö

```bash
# –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å venv
.\.venv\Scripts\activate

# –ó–∞–ø—É—Å—Ç–∏—Ç—å PHASE 3
python scripts\train_ensemble_cross_validation.py

# –û–∂–∏–¥–∞–µ–º–æ–µ –≤—Ä–µ–º—è: ~1 —á–∞—Å
# (5 folds √ó 3 models √ó 30 trials √ó ~40 sec/trial)
```

**Output:**
- `artifacts/ensemble_<model>_cv_<timestamp>.pkl` - –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å
- `artifacts/ensemble_metadata_cv_<timestamp>.json` - –º–µ—Ç—Ä–∏–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

---

## üìà –û–ñ–ò–î–ê–ï–ú–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: SUCCESS (Test AUC >0.55)

```
PHASE 2 (Single Val):  Test AUC = 0.4829
PHASE 3 (Cross-Val):   Test AUC = 0.5800 (+20% improvement)

[SUCCESS] Overfitting fixed!

[NEXT STEPS]
1. Backtest —Å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
2. Paper trading monitoring
3. (Optional) Threshold optimization
```

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: PARTIAL SUCCESS (Test AUC 0.50-0.55)

```
PHASE 2 (Single Val):  Test AUC = 0.4829
PHASE 3 (Cross-Val):   Test AUC = 0.5200 (+7.7% improvement)

[PARTIAL SUCCESS] Improvement detected, but more work needed

[NEXT STEPS]
1. –£–≤–µ–ª–∏—á–∏—Ç—å N_SPLITS (10-fold CV)
2. –ó–∞–≥—Ä—É–∑–∏—Ç—å –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (6+ –º–µ—Å—è—Ü–µ–≤)
3. Feature engineering (–¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏)
```

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: FAILURE (Test AUC <0.50)

```
PHASE 2 (Single Val):  Test AUC = 0.4829
PHASE 3 (Cross-Val):   Test AUC = 0.4900 (+1.5% improvement)

[WARNING] No significant improvement

[NEXT STEPS]
1. –£–≤–µ–ª–∏—á–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç (>10,000 samples)
2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ horizon_steps (12h, 24h)
3. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å RL-–ø–æ–¥—Ö–æ–¥ –≤–º–µ—Å—Ç–æ supervised learning
4. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ø—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å (Logistic Regression)
```

---

## üîç –ê–ù–ê–õ–ò–ó –ü–û–°–õ–ï –ó–ê–ü–£–°–ö–ê

### –í–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

1. **–ï—Å—Ç—å –ª–∏ overfitting?**
   - Validation AUC >> Test AUC ‚Üí –î–ê
   - Validation AUC ‚âà Test AUC ‚Üí –ù–ï–¢

2. **Stable –ª–∏ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ CV folds?**
   - std(AUC) <0.05 ‚Üí –°—Ç–∞–±–∏–ª—å–Ω–æ
   - std(AUC) >0.10 ‚Üí –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ (–ø—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏)

3. **–ü–æ–º–æ–≥–ª–∞ –ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è?**
   - –°—Ä–∞–≤–Ω–∏—Ç—å PHASE 2 params vs PHASE 3 params
   - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å feature importance (—Ç–æ–ø-20 —Ñ–∏—á)

---

## üìö LESSONS LEARNED

### –ß—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –≤ PHASE 2?

1. **Single Validation Split**
   - Optuna –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–ª –ø–æ–¥ –æ–¥–∏–Ω —Ñ–æ–ª–¥
   - Validation set —Å—Ç–∞–ª "—á–∞—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è"

2. **–°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è –º–æ–¥–µ–ª—å**
   - max_depth=10 ‚Üí overfitting
   - min_child_weight=1 ‚Üí –º–∞–ª–µ–Ω—å–∫–∏–µ —É–∑–ª—ã
   - reg_lambda=1.0-5.0 ‚Üí –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

3. **–ù–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ overfitting**
   - Validation AUC –≤—ã–≥–ª—è–¥–µ–ª –æ—Ç–ª–∏—á–Ω–æ (0.6538)
   - Test AUC –ø–æ–∫–∞–∑–∞–ª —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å (0.4829)

### –ß—Ç–æ –∏—Å–ø—Ä–∞–≤–∏–ª–∏ –≤ PHASE 3?

1. ‚úÖ **TimeSeriesSplit (5-fold CV)**
2. ‚úÖ **–£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**
3. ‚úÖ **–ë–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏** (–º–µ–Ω—å—à–µ max_depth)
4. ‚úÖ **Aggregation params** (—É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ —Ñ–æ–ª–¥–∞–º)

---

## üéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ú–ï–¢–†–ò–ö–ò

| –ú–µ—Ç—Ä–∏–∫–∞ | PHASE 2 | PHASE 3 (–¶–µ–ª—å) |
|---------|---------|----------------|
| Test AUC | 0.4829 | >0.55 (–º–∏–Ω–∏–º—É–º), >0.60 (–∏–¥–µ–∞–ª) |
| Validation AUC | 0.6538 | <0.65 (–Ω–µ –¥–æ–ª–∂–Ω–∞ —Ä–∞—Å—Ç–∏) |
| Val-Test Gap | +0.1709 | <0.05 (–Ω–µ—Ç overfitting!) |
| Sharpe (Backtest) | -1.98 | >1.0 |
| Total Return | -2.56% | >3% |

---

## üìù –ò–¢–û–ì–ò

- **PHASE 2:** Feature Selection + Optuna ‚Üí overfitting –æ–±–Ω–∞—Ä—É–∂–µ–Ω
- **PHASE 3:** Cross-Validation + —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è ‚Üí –æ–∂–∏–¥–∞–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
- **–í—Ä–µ–º—è:** ~1 —á–∞—Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- **–†–∏—Å–∫:** –ï—Å–ª–∏ –Ω–µ –ø–æ–º–æ–∂–µ—Ç, –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –ø–æ–¥—Ö–æ–¥ (RL, –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –¥—Ä—É–≥–∏–µ —Ñ–∏—á–∏)

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-12 –≤–µ—á–µ—Ä  
**–ê–≤—Ç–æ—Ä:** AI Assistant (Claude Sonnet 4.5)  
**–°—Ç–∞—Ç—É—Å:** –ì–æ—Ç–æ–≤ –∫ –∑–∞–ø—É—Å–∫—É

